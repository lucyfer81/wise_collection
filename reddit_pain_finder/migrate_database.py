#!/usr/bin/env python3
"""
Database Migration Script
è¿ç§»ç°æœ‰Redditæ•°æ®åˆ°æ–°çš„å¤šæ•°æ®æºschema
"""
import os
import sys
import sqlite3
import json
import logging
from datetime import datetime
from typing import List, Dict, Any

# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from utils.db import WiseCollectionDB

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DatabaseMigrator:
    """æ•°æ®åº“è¿ç§»å™¨"""

    def __init__(self, db_path: str = "data/reddit_pain_finder.db"):
        """åˆå§‹åŒ–è¿ç§»å™¨"""
        self.db_path = db_path
        self.db = WiseCollectionDB()
        self.migration_stats = {
            "posts_migrated": 0,
            "posts_failed": 0,
            "backup_created": False,
            "migration_completed": False
        }

    def create_backup(self) -> bool:
        """åˆ›å»ºæ•°æ®åº“å¤‡ä»½"""
        try:
            backup_path = f"{self.db_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            # è¿æ¥æ•°æ®åº“æ‰§è¡Œå¤‡ä»½
            source = sqlite3.connect(self.db_path)
            backup = sqlite3.connect(backup_path)

            source.backup(backup)
            source.close()
            backup.close()

            logger.info(f"Database backup created at: {backup_path}")
            self.migration_stats["backup_created"] = True
            return True

        except Exception as e:
            logger.error(f"Failed to create backup: {e}")
            return False

    def check_migration_needed(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦è¿ç§»"""
        try:
            with self.db.get_connection("raw") as conn:
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ–°å­—æ®µ
                cursor = conn.execute("PRAGMA table_info(posts)")
                columns = [row['name'] for row in cursor.fetchall()]

                needed_columns = ['source', 'source_id', 'platform_data', 'created_at']
                missing_columns = [col for col in needed_columns if col not in columns]

                if missing_columns:
                    logger.info(f"Migration needed. Missing columns: {missing_columns}")
                    return True
                else:
                    logger.info("Database schema already up to date")
                    return False

        except Exception as e:
            logger.error(f"Failed to check migration status: {e}")
            return False

    def add_new_columns(self) -> bool:
        """æ·»åŠ æ–°çš„æ•°æ®åˆ—"""
        try:
            with self.db.get_connection("raw") as conn:
                # æ£€æŸ¥ç°æœ‰åˆ—
                cursor = conn.execute("PRAGMA table_info(posts)")
                existing_columns = {row['name'] for row in cursor.fetchall()}

                # æ·»åŠ æ–°åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                new_columns = [
                    ("source", "TEXT NOT NULL DEFAULT 'reddit'"),
                    ("source_id", "TEXT NOT NULL"),
                    ("platform_data", "TEXT"),
                    ("created_at", "TIMESTAMP NOT NULL")
                ]

                for col_name, col_def in new_columns:
                    if col_name not in existing_columns:
                        logger.info(f"Adding column: {col_name}")
                        conn.execute(f"ALTER TABLE posts ADD COLUMN {col_name} {col_def}")

                # æ·»åŠ å”¯ä¸€çº¦æŸï¼ˆå¯èƒ½éœ€è¦å…ˆå¤„ç†é‡å¤æ•°æ®ï¼‰
                try:
                    conn.execute("CREATE UNIQUE INDEX IF NOT EXISTS idx_posts_unique_source ON posts(source, source_id)")
                    conn.execute("CREATE INDEX IF NOT EXISTS idx_posts_source ON posts(source)")
                    conn.execute("CREATE INDEX IF NOT EXISTS idx_posts_source_created ON posts(source, created_at)")
                except Exception as e:
                    logger.warning(f"Could not create unique constraint (will handle duplicates): {e}")

                conn.commit()
                logger.info("New columns added successfully")
                return True

        except Exception as e:
            logger.error(f"Failed to add new columns: {e}")
            return False

    def migrate_posts(self) -> bool:
        """è¿ç§»ç°æœ‰å¸–å­æ•°æ®"""
        try:
            with self.db.get_connection("raw") as conn:
                # è·å–æ‰€æœ‰éœ€è¦è¿ç§»çš„å¸–å­ï¼ˆæ²¡æœ‰source_idçš„æ—§æ•°æ®ï¼‰
                cursor = conn.execute("""
                    SELECT id, subreddit, upvote_ratio, is_self, created_utc, url, title, body,
                           score, num_comments, author, category, raw_data
                    FROM posts
                    WHERE source_id IS NULL OR source_id = ''
                """)

                posts = cursor.fetchall()
                logger.info(f"Found {len(posts)} posts to migrate")

                for post in posts:
                    try:
                        # æå–æ•°æ®
                        reddit_id = post['id']
                        unified_id = f"reddit_{reddit_id}"

                        # æ„å»ºplatform_data
                        platform_data = {
                            "subreddit": post['subreddit'],
                            "upvote_ratio": post['upvote_ratio'],
                            "is_self": bool(post['is_self']),
                            "reddit_url": post['url']
                        }

                        # æ ‡å‡†åŒ–æ—¶é—´
                        created_at = datetime.fromtimestamp(post['created_utc']).isoformat() + "Z"

                        # æ›´æ–°è®°å½•
                        conn.execute("""
                            UPDATE posts SET
                                id = ?,
                                source = 'reddit',
                                source_id = ?,
                                platform_data = ?,
                                created_at = ?
                            WHERE id = ?
                        """, (
                            unified_id,
                            reddit_id,
                            json.dumps(platform_data),
                            created_at,
                            reddit_id  # åŸå§‹ID
                        ))

                        self.migration_stats["posts_migrated"] += 1

                        if self.migration_stats["posts_migrated"] % 100 == 0:
                            logger.info(f"Migrated {self.migration_stats['posts_migrated']} posts...")

                    except Exception as e:
                        logger.error(f"Failed to migrate post {post.get('id')}: {e}")
                        self.migration_stats["posts_failed"] += 1
                        continue

                conn.commit()
                logger.info(f"Migration completed. Success: {self.migration_stats['posts_migrated']}, Failed: {self.migration_stats['posts_failed']}")
                return True

        except Exception as e:
            logger.error(f"Failed to migrate posts: {e}")
            return False

    def update_filtered_posts(self) -> bool:
        """æ›´æ–°filtered_postsè¡¨çš„IDå¼•ç”¨"""
        try:
            with self.db.get_connection("filtered") as conn:
                # è·å–æ‰€æœ‰filtered posts
                cursor = conn.execute("SELECT DISTINCT id FROM filtered_posts")
                filtered_ids = [row['id'] for row in cursor.fetchall()]

                logger.info(f"Updating {len(filtered_ids)} filtered post references")

                updated_count = 0
                for old_id in filtered_ids:
                    try:
                        new_id = f"reddit_{old_id}"
                        conn.execute("UPDATE filtered_posts SET id = ? WHERE id = ?", (new_id, old_id))
                        updated_count += 1
                    except Exception as e:
                        logger.error(f"Failed to update filtered post {old_id}: {e}")
                        continue

                conn.commit()
                logger.info(f"Updated {updated_count} filtered post references")
                return True

        except Exception as e:
            logger.error(f"Failed to update filtered posts: {e}")
            return False

    def update_pain_events(self) -> bool:
        """æ›´æ–°pain_eventsè¡¨çš„post_idå¼•ç”¨"""
        try:
            with self.db.get_connection("pain") as conn:
                # è·å–æ‰€æœ‰pain events
                cursor = conn.execute("SELECT DISTINCT post_id FROM pain_events")
                post_ids = [row['post_id'] for row in cursor.fetchall()]

                logger.info(f"Updating {len(post_ids)} pain event references")

                updated_count = 0
                for old_id in post_ids:
                    try:
                        new_id = f"reddit_{old_id}"
                        conn.execute("UPDATE pain_events SET post_id = ? WHERE post_id = ?", (new_id, old_id))
                        updated_count += 1
                    except Exception as e:
                        logger.error(f"Failed to update pain events for post {old_id}: {e}")
                        continue

                conn.commit()
                logger.info(f"Updated {updated_count} pain event references")
                return True

        except Exception as e:
            logger.error(f"Failed to update pain events: {e}")
            return False

    def verify_migration(self) -> bool:
        """éªŒè¯è¿ç§»ç»“æœ"""
        try:
            with self.db.get_connection("raw") as conn:
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªè¿ç§»çš„å¸–å­
                cursor = conn.execute("SELECT COUNT(*) as count FROM posts WHERE source_id IS NULL OR source_id = ''")
                unmigrated_count = cursor.fetchone()['count']

                # æ£€æŸ¥æ€»æ•°
                cursor = conn.execute("SELECT COUNT(*) as total FROM posts")
                total_count = cursor.fetchone()['total']

                # æ£€æŸ¥æŒ‰æ•°æ®æºåˆ†ç»„
                cursor = conn.execute("SELECT source, COUNT(*) as count FROM posts GROUP BY source")
                source_counts = {row['source']: row['count'] for row in cursor.fetchall()}

                logger.info(f"Migration verification:")
                logger.info(f"  Total posts: {total_count}")
                logger.info(f"  Unmigrated posts: {unmigrated_count}")
                logger.info(f"  Posts by source: {source_counts}")

                if unmigrated_count == 0:
                    logger.info("âœ… Migration successful!")
                    return True
                else:
                    logger.warning(f"âš ï¸ Migration incomplete: {unmigrated_count} posts still unmigrated")
                    return False

        except Exception as e:
            logger.error(f"Failed to verify migration: {e}")
            return False

    def run_migration(self) -> bool:
        """æ‰§è¡Œå®Œæ•´è¿ç§»æµç¨‹"""
        logger.info("ğŸš€ Starting database migration...")

        # 1. åˆ›å»ºå¤‡ä»½
        if not self.create_backup():
            logger.error("âŒ Migration failed: Could not create backup")
            return False

        # 2. æ£€æŸ¥æ˜¯å¦éœ€è¦è¿ç§»
        if not self.check_migration_needed():
            logger.info("âœ… Migration not needed - schema already up to date")
            return True

        # 3. æ·»åŠ æ–°åˆ—
        if not self.add_new_columns():
            logger.error("âŒ Migration failed: Could not add new columns")
            return False

        # 4. è¿ç§»å¸–å­æ•°æ®
        if not self.migrate_posts():
            logger.error("âŒ Migration failed: Could not migrate posts")
            return False

        # 5. æ›´æ–°å¼•ç”¨
        if not self.update_filtered_posts():
            logger.error("âŒ Migration failed: Could not update filtered posts")
            return False

        if not self.update_pain_events():
            logger.error("âŒ Migration failed: Could not update pain events")
            return False

        # 6. éªŒè¯è¿ç§»
        if not self.verify_migration():
            logger.error("âŒ Migration failed: Verification failed")
            return False

        # 7. é‡æ–°åˆ›å»ºç´¢å¼•
        try:
            with self.db.get_connection("raw") as conn:
                conn.execute("DROP INDEX IF EXISTS idx_posts_unique_source")
                conn.execute("CREATE UNIQUE INDEX idx_posts_unique_source ON posts(source, source_id)")
                conn.commit()
            logger.info("âœ… Indexes recreated successfully")
        except Exception as e:
            logger.warning(f"Could not recreate unique index: {e}")

        self.migration_stats["migration_completed"] = True

        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        logger.info("=" * 50)
        logger.info("MIGRATION SUMMARY")
        logger.info("=" * 50)
        logger.info(f"Posts migrated: {self.migration_stats['posts_migrated']}")
        logger.info(f"Posts failed: {self.migration_stats['posts_failed']}")
        logger.info(f"Backup created: {self.migration_stats['backup_created']}")
        logger.info(f"Migration completed: {self.migration_stats['migration_completed']}")
        logger.info("=" * 50)

        return True

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="Migrate database to multi-source schema")
    parser.add_argument("--db-path", default="data/reddit_pain_finder.db", help="Database file path")
    parser.add_argument("--force", action="store_true", help="Force migration even if not needed")
    args = parser.parse_args()

    try:
        migrator = DatabaseMigrator(args.db_path)

        if not args.force and not migrator.check_migration_needed():
            print("Database schema already up to date. Use --force to run migration anyway.")
            return

        success = migrator.run_migration()

        if success:
            print("âœ… Migration completed successfully!")
            sys.exit(0)
        else:
            print("âŒ Migration failed!")
            sys.exit(1)

    except KeyboardInterrupt:
        logger.info("Migration interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Migration failed with error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()