# dashboard.py
import streamlit as st
import pandas as pd
import requests
import json
import sys

# --- Page Configuration ---
st.set_page_config(
    page_title="æ™ºèƒ½è¶‹åŠ¿åˆ†æä»ªè¡¨ç›˜",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# --- Database Connection ---
@st.cache_resource
def get_db_connection():
    """Caches the database connection using HTTP API."""
    try:
        # These secrets are set in the Streamlit Cloud dashboard
        db_url = st.secrets["DB_URL"]
        auth_token = st.secrets["DB_AUTH_TOKEN"]
        
        # Extract database name from URL
        db_name = "wisecollection"
        
        # Create HTTP API URL
        api_url = f"https://{db_url.replace('libsql://', '')}/v2/pipeline"
        
        return {
            'api_url': api_url,
            'auth_token': auth_token,
            'db_name': db_name
        }
    except Exception as e:
        st.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        st.error("è¯·ç¡®ä¿æ‚¨å·²åœ¨ Streamlit Cloud çš„ Secrets ä¸­æ­£ç¡®è®¾ç½®äº† DB_URL å’Œ DB_AUTH_TOKENã€‚")
        sys.exit(1)

def execute_query(conn_info, query):
    """Execute SQL query using HTTP API"""
    try:
        headers = {
            'Authorization': f'Bearer {conn_info["auth_token"]}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'requests': [
                {
                    'type': 'execute',
                    'stmt': {
                        'sql': query
                    }
                }
            ]
        }
        
        response = requests.post(conn_info['api_url'], headers=headers, json=payload)
        
        if response.status_code == 200:
            result = response.json()
            if 'results' in result and len(result['results']) > 0:
                query_result = result['results'][0]['response']['result']
                if 'rows' in query_result:
                    # Extract values from rows
                    extracted_rows = []
                    for row in query_result['rows']:
                        extracted_row = []
                        for cell in row:
                            if isinstance(cell, dict) and 'value' in cell:
                                extracted_row.append(cell['value'])
                            else:
                                extracted_row.append(cell)
                        extracted_rows.append(extracted_row)
                    return extracted_rows
            return []
        else:
            st.error(f"Query failed: {response.status_code} - {response.text}")
            return []
    except Exception as e:
        st.error(f"Query error: {e}")
        return []

conn = get_db_connection()

# --- Database Table Check ---
try:
    # é¦–å…ˆå°è¯•ç›´æ¥æŸ¥è¯¢topicsè¡¨
    count_rows = execute_query(conn, "SELECT COUNT(*) FROM topics;")
    if count_rows:
        count = count_rows[0][0]
        st.success(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼topicsè¡¨åŒ…å« {count} æ¡æ•°æ®")
    else:
        st.warning("topicsè¡¨ä¸å­˜åœ¨æˆ–ä¸ºç©º")
        
except Exception as e:
    st.error(f"æ•°æ®åº“è¡¨æ£€æŸ¥å¤±è´¥: {e}")

# --- Data Loading Functions ---
@st.cache_data(ttl=600) # Cache data for 10 minutes
def load_data(query, column_names=None):
    """Loads data from the database using a given query."""
    try:
        rows = execute_query(conn, query)
        if rows:
            # Convert rows to DataFrame
            if column_names:
                # Use provided column names
                return pd.DataFrame(rows, columns=column_names)
            elif query.startswith("SELECT"):
                # Extract column names from query
                columns = []
                if "SELECT" in query.upper():
                    # Simple column name extraction
                    select_part = query.upper().split("SELECT")[1].split("FROM")[0].strip()
                    columns = [col.strip() for col in select_part.split(",")]
                
                # Clean up column names
                clean_columns = []
                for col in columns:
                    if " AS " in col.upper():
                        clean_columns.append(col.split(" AS ")[-1].strip())
                    elif "." in col:
                        clean_columns.append(col.split(".")[-1].strip())
                    else:
                        clean_columns.append(col.strip())
                
                return pd.DataFrame(rows, columns=clean_columns)
            else:
                return pd.DataFrame(rows)
        else:
            return pd.DataFrame()
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return pd.DataFrame()

# --- UI Layout ---
st.title("ğŸ“ˆ æ™ºèƒ½è¶‹åŠ¿åˆ†æä»ªè¡¨ç›˜")
st.markdown("ä¸€ä¸ªç”¨äºæ¢ç´¢å’Œåˆ†æ AI é¢†åŸŸæ–°å…´ä¸»é¢˜çš„åŠ¨æ€ä»ªè¡¨ç›˜ã€‚")

# --- Sidebar for Filters ---
st.sidebar.header("ğŸ” ç­›é€‰ä¸æœç´¢")
search_term = st.sidebar.text_input("åœ¨ä¸»é¢˜æ‘˜è¦ä¸­æœç´¢å…³é”®è¯")

# --- Main Content ---
tab1, tab2 = st.tabs(["ğŸ“… æœ€æ–°ä¸»é¢˜æ¦‚è§ˆ", "ğŸ“š æ‰€æœ‰ä¸»é¢˜æ•°æ®åº“"])

with tab1:
    st.header("æœ€è¿‘åˆ†æçš„ä¸»é¢˜")
    recent_topics_df = load_data("SELECT created_at, topic_name, topic_keywords, summary_chinese FROM topics ORDER BY created_at DESC LIMIT 50", 
                               column_names=['created_at', 'topic_name', 'topic_keywords', 'summary_chinese'])

    if recent_topics_df.empty:
        st.warning("æ•°æ®åº“ä¸­è¿˜æ²¡æœ‰ä»»ä½•ä¸»é¢˜ã€‚è¯·å…ˆè¿è¡Œåˆ†æè„šæœ¬ã€‚")
    else:
        # Apply search filter
        if search_term:
            recent_topics_df = recent_topics_df[recent_topics_df['summary_chinese'].str.contains(search_term, case=False, na=False)]

        st.metric("æ€»ä¸»é¢˜æ•°", len(recent_topics_df))
        st.dataframe(recent_topics_df, use_container_width=True)

with tab2:
    st.header("ä¸»é¢˜æ•°æ®åº“å…¨è§ˆ")
    all_topics_df = load_data("SELECT id, created_at, topic_name, topic_keywords, summary_english, summary_chinese FROM topics ORDER BY id DESC",
                               column_names=['id', 'created_at', 'topic_name', 'topic_keywords', 'summary_english', 'summary_chinese'])

    if all_topics_df.empty:
        st.warning("æ•°æ®åº“ä¸­è¿˜æ²¡æœ‰ä»»ä½•ä¸»é¢˜ã€‚")
    else:
        # Apply search filter
        if search_term:
            all_topics_df = all_topics_df[all_topics_df['summary_chinese'].str.contains(search_term, case=False, na=False) | all_topics_df['summary_english'].str.contains(search_term, case=False, na=False)]

        st.dataframe(all_topics_df, use_container_width=True)

        # Expander for details
        st.subheader("æŸ¥çœ‹å•ä¸ªä¸»é¢˜è¯¦æƒ…")
        selected_id = st.selectbox("é€‰æ‹©ä¸€ä¸ªä¸»é¢˜IDè¿›è¡ŒæŸ¥çœ‹:", options=all_topics_df['id'])
        if selected_id:
            selected_topic = all_topics_df[all_topics_df['id'] == selected_id].iloc[0]
            st.markdown(f"### {selected_topic['topic_name']}")
            st.markdown("#### ä¸­æ–‡æˆ˜ç•¥ç®€æŠ¥")
            st.markdown(selected_topic['summary_chinese'], unsafe_allow_html=True)
            with st.expander("æŸ¥çœ‹è‹±æ–‡åŸæ–‡"):
                st.markdown(selected_topic['summary_english'], unsafe_allow_html=True)

st.sidebar.info("æŠ¥å‘Šç”± Wise Collection é¡¹ç›®è‡ªåŠ¨ç”Ÿæˆã€‚")
