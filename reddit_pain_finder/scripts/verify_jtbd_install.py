#!/usr/bin/env python3
"""JTBDåŠŸèƒ½å®‰è£…éªŒè¯ï¼ˆæ— éœ€APIï¼‰"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.db import db
import json

def main():
    print("=" * 80)
    print("JTBDäº§å“è¯­ä¹‰å‡çº§ - å®‰è£…éªŒè¯")
    print("=" * 80)

    # 1. æ•°æ®åº“schemaéªŒè¯
    print("\n[1/3] éªŒè¯æ•°æ®åº“schema...")
    with db.get_connection("clusters") as conn:
        cursor = conn.execute("PRAGMA table_info(clusters)")
        columns = {row['name'] for row in cursor.fetchall()}

        jtbd_columns = ['job_statement', 'job_steps', 'desired_outcomes',
                        'job_context', 'customer_profile', 'semantic_category', 'product_impact']

        missing = [col for col in jtbd_columns if col not in columns]
        if missing:
            print(f"âŒ ç¼ºå°‘å­—æ®µ: {missing}")
            return False
        else:
            print(f"âœ… æ‰€æœ‰JTBDå­—æ®µå·²å­˜åœ¨:")
            for col in jtbd_columns:
                print(f"   - {col}")

    # 2. æ£€æŸ¥ç´¢å¼•
    print("\n[2/3] éªŒè¯ç´¢å¼•...")
    with db.get_connection("clusters") as conn:
        cursor = conn.execute("SELECT name FROM sqlite_master WHERE type='index' AND name LIKE 'idx_clusters_%'")
        indexes = [row['name'] for row in cursor.fetchall()]

        expected_indexes = ['idx_clusters_semantic_category', 'idx_clusters_product_impact']
        for idx in expected_indexes:
            if idx in indexes:
                print(f"âœ… ç´¢å¼•å­˜åœ¨: {idx}")
            else:
                print(f"âš ï¸  ç´¢å¼•ç¼ºå¤±: {idx}")

    # 3. æ£€æŸ¥ä»£ç æ¨¡å—
    print("\n[3/3] éªŒè¯ä»£ç æ¨¡å—...")
    try:
        # æ£€æŸ¥LLMå®¢æˆ·ç«¯
        from utils.llm_client import llm_client
        if hasattr(llm_client, 'generate_jtbd_from_cluster'):
            print("âœ… LLMå®¢æˆ·ç«¯å·²æ›´æ–° (generate_jtbd_from_clusterå­˜åœ¨)")
        else:
            print("âŒ LLMå®¢æˆ·ç«¯æœªæ›´æ–°")

        # æ£€æŸ¥èšç±»å™¨
        from pipeline.cluster import PainEventClusterer
        clusterer = PainEventClusterer()

        methods = ['get_clusters_by_semantic_category', 'get_high_impact_clusters', 'get_all_semantic_categories']
        for method in methods:
            if hasattr(clusterer, method):
                print(f"âœ… èšç±»å™¨æ–¹æ³•å­˜åœ¨: {method}")
            else:
                print(f"âŒ èšç±»å™¨æ–¹æ³•ç¼ºå¤±: {method}")

    except Exception as e:
        print(f"âŒ ä»£ç æ¨¡å—éªŒè¯å¤±è´¥: {e}")
        return False

    # 4. æ£€æŸ¥ç°æœ‰æ•°æ®
    print("\n[æ•°æ®ç»Ÿè®¡]")
    with db.get_connection("clusters") as conn:
        cursor = conn.execute("SELECT COUNT(*) as count FROM clusters")
        cluster_count = cursor.fetchone()["count"]

        if cluster_count > 0:
            cursor = conn.execute("""
                SELECT
                    COUNT(*) as total,
                    SUM(CASE WHEN job_statement IS NOT NULL AND job_statement != '' THEN 1 ELSE 0 END) as with_jtbd
                FROM clusters
            """)
            result = cursor.fetchone()
            print(f"æ€»clusters: {result['total']}")
            print(f"å·²æœ‰JTBD: {result['with_jtbd']}")
            print(f"éœ€è¦è¿ç§»: {result['total'] - result['with_jtbd']}")
        else:
            print("æ— ç°æœ‰clusters")

    print("\n" + "=" * 80)
    print("âœ… å®‰è£…éªŒè¯å®Œæˆï¼æ‰€æœ‰ç»„ä»¶å°±ç»ªã€‚")
    print("=" * 80)

    print("\nğŸ“ ä½¿ç”¨æŒ‡å—:")
    print("\n1. ä¸ºç°æœ‰clustersç”ŸæˆJTBD:")
    print("   python3 scripts/migrate_existing_clusters_to_jtbd.py")
    print("\n2. ç”Ÿæˆæ–°çš„clustersï¼ˆè‡ªåŠ¨åŒ…å«JTBDï¼‰:")
    print("   export Siliconflow_KEY=your_key_here")
    print("   python3 pipeline/cluster.py")
    print("\n3. æŸ¥è¯¢JTBDæ•°æ®:")
    print("   from pipeline.cluster import PainEventClusterer")
    print("   clusterer = PainEventClusterer()")
    print("   high_impact = clusterer.get_high_impact_clusters(min_impact=0.7)")
    print("   categories = clusterer.get_all_semantic_categories()")

if __name__ == "__main__":
    main()
