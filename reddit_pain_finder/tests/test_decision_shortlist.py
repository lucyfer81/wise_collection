# tests/test_decision_shortlist.py
"""Tests for Decision Shortlist Generator"""
import pytest
import json
from pipeline.decision_shortlist import DecisionShortlistGenerator
from utils.db import db


def test_apply_hard_filters():
    """æµ‹è¯•ç¡¬æ€§è¿‡æ»¤é€»è¾‘"""
    generator = DecisionShortlistGenerator()

    result = generator._apply_hard_filters()

    # éªŒè¯è¿”å›å€¼æ˜¯åˆ—è¡¨
    assert isinstance(result, list)

    # éªŒè¯æ¯ä¸ªæœºä¼šéƒ½æ»¡è¶³è¿‡æ»¤æ¡ä»¶
    for opp in result:
        assert opp['viability_score'] >= 7.0, f"viability {opp['viability_score']} < 7.0"
        assert opp['cluster_size'] >= 6, f"cluster_size {opp['cluster_size']} < 6"
        assert opp['trust_level'] >= 0.7, f"trust_level {opp['trust_level']} < 0.7"


def test_apply_hard_filters_with_test_data():
    """æµ‹è¯•ç¡¬æ€§è¿‡æ»¤é€»è¾‘ï¼ˆä½¿ç”¨æµ‹è¯•æ•°æ®ï¼‰"""
    generator = DecisionShortlistGenerator()

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    try:
        with db.get_connection("clusters") as conn:
            # åˆ›å»ºæµ‹è¯•èšç±»
            conn.execute("""
                INSERT INTO clusters (cluster_name, cluster_description, source_type,
                                    centroid_summary, pain_event_ids, cluster_size)
                VALUES
                    ('high_quality_cluster', 'High quality cluster', 'reddit',
                     'Summary', '[1,2,3]', 10),
                    ('low_quality_cluster', 'Low quality cluster', 'reddit',
                     'Summary', '[4,5]', 3),
                    ('medium_quality_cluster', 'Medium quality cluster', 'reddit',
                     'Summary', '[6,7,8,9,10]', 5),
                    ('ignored_cluster', 'Should be ignored', 'reddit',
                     'Summary', '[11,12]', 8)
            """)
            conn.commit()

            # è·å–èšç±»ID
            clusters = conn.execute("SELECT id, cluster_name FROM clusters").fetchall()
            cluster_map = {name: id for id, name in clusters}

            # åˆ›å»ºæµ‹è¯•æœºä¼š
            conn.execute("""
                INSERT INTO opportunities (cluster_id, opportunity_name, description,
                                         total_score, trust_level, target_users,
                                         missing_capability, why_existing_fail)
                VALUES
                    (?, 'High Viability Opportunity', 'Great opportunity',
                     8.5, 0.8, 'Users', 'Capability', 'Reason'),
                    (?, 'Low Viability Opportunity', 'Not viable',
                     5.0, 0.8, 'Users', 'Capability', 'Reason'),
                    (?, 'Low Trust Opportunity', 'Low trust',
                     8.0, 0.5, 'Users', 'Capability', 'Reason'),
                    (?, 'Ignored Cluster Opportunity', 'Should be ignored',
                     9.0, 0.9, 'Users', 'Capability', 'Reason')
            """, (
                cluster_map['high_quality_cluster'],
                cluster_map['low_quality_cluster'],
                cluster_map['medium_quality_cluster'],
                cluster_map['ignored_cluster']
            ))
            conn.commit()

            # è®¾ç½®å¿½ç•¥çš„èšç±»
            generator.config['ignored_clusters'] = ['ignored_cluster']

            # è¿è¡Œè¿‡æ»¤
            result = generator._apply_hard_filters()

            # éªŒè¯ç»“æœ
            assert len(result) == 1, f"Expected 1 opportunity, got {len(result)}"
            assert result[0]['opportunity_name'] == 'High Viability Opportunity'
            assert result[0]['viability_score'] == 8.5
            assert result[0]['cluster_size'] == 10
            assert result[0]['trust_level'] == 0.8

            # æ¸…ç†æµ‹è¯•æ•°æ®
            conn.execute("DELETE FROM opportunities")
            conn.execute("DELETE FROM clusters")
            conn.commit()

    except Exception as e:
        pytest.fail(f"Test failed with exception: {e}")


def test_apply_hard_filters_error_handling():
    """æµ‹è¯•ç¡¬æ€§è¿‡æ»¤çš„é”™è¯¯å¤„ç†"""
    generator = DecisionShortlistGenerator()

    # ä½¿ç”¨æ— æ•ˆçš„æ•°æ®åº“è·¯å¾„æ¥æµ‹è¯•é”™è¯¯å¤„ç†
    original_config = generator.config
    generator.config['min_viability_score'] = 'invalid'  # æ— æ•ˆå€¼

    # åº”è¯¥è¿”å›ç©ºåˆ—è¡¨è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
    result = generator._apply_hard_filters()
    assert isinstance(result, list)
    assert len(result) == 0

    # æ¢å¤é…ç½®
    generator.config = original_config


def test_check_cross_source_validation():
    """æµ‹è¯•è·¨æºéªŒè¯é€»è¾‘"""
    generator = DecisionShortlistGenerator()

    # Test Level 1: source_type='aligned'
    mock_opp = {
        'cluster_id': 1,
        'cluster_name': 'test_cluster',
        'cluster_size': 15,
        'source_type': 'aligned',
        'pain_event_ids': [1, 2, 3, 4, 5]
    }

    result = generator._check_cross_source_validation(mock_opp)

    assert result['has_cross_source'] == True
    assert result['validation_level'] == 1
    assert result['boost_score'] == 2.0
    assert result['validated_problem'] == True
    assert result['evidence'] == "source_type='aligned'"


def test_cross_source_validation_no_pain_events():
    """æµ‹è¯•æ²¡æœ‰ pain events çš„æƒ…å†µ"""
    generator = DecisionShortlistGenerator()

    mock_opp = {
        'cluster_id': 1,
        'cluster_name': 'test_cluster',
        'cluster_size': 15,
        'source_type': 'reddit',
        'pain_event_ids': []  # Empty list
    }

    result = generator._check_cross_source_validation(mock_opp)

    assert result['has_cross_source'] == False
    assert result['validation_level'] == 0
    assert result['boost_score'] == 0.0
    assert result['validated_problem'] == False
    assert result['evidence'] == "No pain events"


def test_cross_source_validation_level3():
    """æµ‹è¯• Level 3 éªŒè¯ï¼ˆä¸­ç­‰èšç±»ï¼Œ2ä¸ªsubredditï¼‰"""
    generator = DecisionShortlistGenerator()

    # Create test data with multiple subreddits
    try:
        with db.get_connection("pain") as conn:
            # Create test posts from different subreddits
            conn.execute("""
                INSERT INTO filtered_posts (title, body, subreddit, url, score, num_comments, upvote_ratio, pain_score)
                VALUES
                    ('Test 1', 'Body 1', 'test_subreddit_1', 'http://test1.com', 10, 5, 0.8, 0.7),
                    ('Test 2', 'Body 2', 'test_subreddit_2', 'http://test2.com', 10, 5, 0.8, 0.7),
                    ('Test 3', 'Body 3', 'test_subreddit_1', 'http://test3.com', 10, 5, 0.8, 0.7),
                    ('Test 4', 'Body 4', 'test_subreddit_2', 'http://test4.com', 10, 5, 0.8, 0.7)
            """)
            conn.commit()

            # Get post IDs
            posts = conn.execute("SELECT id FROM filtered_posts ORDER BY id DESC LIMIT 4").fetchall()
            post_ids = [p['id'] for p in posts]

            # Create pain events
            for post_id in post_ids:
                conn.execute("""
                    INSERT INTO pain_events (post_id, problem, context)
                    VALUES (?, 'Test pain problem', 'Test context')
                """, (post_id,))
            conn.commit()

            # Get pain event IDs
            pain_events = conn.execute("SELECT id FROM pain_events ORDER BY id DESC LIMIT 4").fetchall()
            pain_event_ids = [pe['id'] for pe in pain_events]

            mock_opp = {
                'cluster_id': 1,
                'cluster_name': 'test_cluster',
                'cluster_size': 8,  # Meets Level 3 threshold
                'source_type': 'reddit',
                'pain_event_ids': pain_event_ids
            }

            result = generator._check_cross_source_validation(mock_opp)

            assert result['has_cross_source'] == True
            assert result['validation_level'] == 3
            assert result['boost_score'] == 0.5
            assert result['validated_problem'] == False  # Level 3 doesn't validate
            assert "Medium cluster" in result['evidence']
            assert "subreddits" in result['evidence']

            # Cleanup
            placeholders = ','.join('?' for _ in pain_event_ids)
            conn.execute(f"DELETE FROM pain_events WHERE id IN ({placeholders})", pain_event_ids)
            placeholders = ','.join('?' for _ in post_ids)
            conn.execute(f"DELETE FROM filtered_posts WHERE id IN ({placeholders})", post_ids)
            conn.commit()

    except Exception as e:
        pytest.fail(f"Test failed with exception: {e}")


def test_cross_source_validation_no_validation():
    """æµ‹è¯•æ²¡æœ‰è·¨æºéªŒè¯çš„æƒ…å†µï¼ˆå°èšç±»ï¼‰"""
    generator = DecisionShortlistGenerator()

    mock_opp = {
        'cluster_id': 1,
        'cluster_name': 'test_cluster',
        'cluster_size': 5,  # Below Level 3 threshold
        'source_type': 'reddit',
        'pain_event_ids': [1, 2]
    }

    result = generator._check_cross_source_validation(mock_opp)

    assert result['has_cross_source'] == False
    assert result['validation_level'] == 0
    assert result['boost_score'] == 0.0
    assert result['validated_problem'] == False
    assert result['evidence'] == "No cross-source validation"


def test_calculate_final_score():
    """æµ‹è¯•æœ€ç»ˆè¯„åˆ†è®¡ç®—"""
    generator = DecisionShortlistGenerator()

    # Test case from specification: viability_score=8.0, cluster_size=50, trust_level=0.8, boost=2.0
    opportunity = {
        'viability_score': 8.0,
        'cluster_size': 50,
        'trust_level': 0.8
    }

    cross_source_info = {
        'has_cross_source': True,
        'boost_score': 2.0
    }

    result = generator._calculate_final_score(opportunity, cross_source_info)

    # Expected calculation:
    # log10(50) â‰ˆ 1.7
    # base = 8.0 * 1.0 + 1.7 * 2.5 + 0.8 * 1.5 = 8.0 + 4.25 + 1.2 = 13.45
    # bonus = 5.0 * 2.0 * 0.1 = 1.0
    # total = 13.45 + 1.0 = 14.45 â†’ capped at 10.0
    assert result == 10.0, f"Expected 10.0 (capped), got {result}"


def test_calculate_final_score_no_cross_source():
    """æµ‹è¯•æ²¡æœ‰è·¨æºéªŒè¯çš„è¯„åˆ†è®¡ç®—"""
    generator = DecisionShortlistGenerator()

    opportunity = {
        'viability_score': 7.0,
        'cluster_size': 10,
        'trust_level': 0.7
    }

    cross_source_info = {
        'has_cross_source': False,
        'boost_score': 0.0
    }

    result = generator._calculate_final_score(opportunity, cross_source_info)

    # Expected calculation:
    # log10(10) = 1.0
    # base = 7.0 * 1.0 + 1.0 * 2.5 + 0.7 * 1.5 = 7.0 + 2.5 + 1.05 = 10.55 â†’ capped at 10.0
    assert result == 10.0, f"Expected 10.0 (capped), got {result}"


def test_calculate_final_score_minimum():
    """æµ‹è¯•æœ€ä½è¯„åˆ†"""
    generator = DecisionShortlistGenerator()

    opportunity = {
        'viability_score': 0.0,
        'cluster_size': 1,
        'trust_level': 0.0
    }

    cross_source_info = {
        'has_cross_source': False,
        'boost_score': 0.0
    }

    result = generator._calculate_final_score(opportunity, cross_source_info)

    # log10(1) = 0
    # base = 0.0 * 1.0 + 0.0 * 2.5 + 0.0 * 1.5 = 0.0
    assert result == 0.0, f"Expected 0.0, got {result}"


def test_get_cross_source_badge_level1():
    """æµ‹è¯• Level 1 å¾½ç« ç”Ÿæˆ"""
    generator = DecisionShortlistGenerator()

    cross_source = {
        'has_cross_source': True,
        'validation_level': 1,
        'boost_score': 2.0
    }

    badge = generator._get_cross_source_badge(cross_source)

    assert 'INDEPENDENT VALIDATION ACROSS REDDIT + HACKER NEWS' in badge
    assert 'ğŸ¯' in badge
    assert 'multiple communities' in badge


def test_get_cross_source_badge_level2():
    """æµ‹è¯• Level 2 å¾½ç« ç”Ÿæˆ"""
    generator = DecisionShortlistGenerator()

    cross_source = {
        'has_cross_source': True,
        'validation_level': 2,
        'boost_score': 1.0
    }

    badge = generator._get_cross_source_badge(cross_source)

    assert 'Multi-Subreddit Validation' in badge
    assert 'âœ“' in badge
    assert '3+ subreddits' in badge
    assert 'strong cluster size' in badge


def test_get_cross_source_badge_level3():
    """æµ‹è¯• Level 3 å¾½ç« ç”Ÿæˆ"""
    generator = DecisionShortlistGenerator()

    cross_source = {
        'has_cross_source': True,
        'validation_level': 3,
        'boost_score': 0.5
    }

    badge = generator._get_cross_source_badge(cross_source)

    assert 'Weak Cross-Source Signal' in badge
    assert 'â—' in badge
    assert 'Initial cross-community detection' in badge


def test_get_cross_source_badge_no_validation():
    """æµ‹è¯•æ²¡æœ‰è·¨æºéªŒè¯æ—¶å¾½ç« ä¸ºç©º"""
    generator = DecisionShortlistGenerator()

    cross_source = {
        'has_cross_source': False,
        'validation_level': 0,
        'boost_score': 0.0
    }

    badge = generator._get_cross_source_badge(cross_source)

    assert badge == ""


def test_markdown_report_includes_badges(tmp_path):
    """æµ‹è¯• Markdown æŠ¥å‘ŠåŒ…å«å¾½ç« """
    import os
    import tempfile

    generator = DecisionShortlistGenerator()

    # Create a mock shortlist with cross-source validation
    shortlist = [
        {
            'opportunity_name': 'Test Opportunity',
            'final_score': 9.0,
            'viability_score': 8.5,
            'cluster_size': 50,
            'trust_level': 0.85,
            'target_users': 'Test users',
            'missing_capability': 'Test capability',
            'why_existing_fail': 'Test reason',
            'readable_content': {
                'problem': 'Test problem',
                'mvp': 'Test MVP',
                'why_now': 'Test timing'
            },
            'cross_source_validation': {
                'has_cross_source': True,
                'validation_level': 1,
                'boost_score': 2.0,
                'validated_problem': True
            }
        }
    ]

    # Temporarily override the output directory
    original_dir = generator.config['output']['markdown_dir']
    generator.config['output']['markdown_dir'] = tmp_path

    # Generate the report
    report_path = generator._export_markdown_report(shortlist)

    # Read the report content
    with open(report_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Restore original directory
    generator.config['output']['markdown_dir'] = original_dir

    # Verify badge is in the report
    assert 'INDEPENDENT VALIDATION ACROSS REDDIT + HACKER NEWS' in content
    assert 'ğŸ¯' in content
    assert 'Validation Level**: 1' in content
    assert 'Boost Applied**: +2.0' in content
    assert 'Validated Problem**: âœ… Yes' in content


def test_markdown_report_no_badge_without_validation(tmp_path):
    """æµ‹è¯•æ²¡æœ‰è·¨æºéªŒè¯æ—¶ä¸æ˜¾ç¤ºå¾½ç« """
    generator = DecisionShortlistGenerator()

    # Create a mock shortlist without cross-source validation
    shortlist = [
        {
            'opportunity_name': 'Test Opportunity',
            'final_score': 7.5,
            'viability_score': 7.5,
            'cluster_size': 10,
            'trust_level': 0.75,
            'target_users': 'Test users',
            'missing_capability': 'Test capability',
            'why_existing_fail': 'Test reason',
            'readable_content': {
                'problem': 'Test problem',
                'mvp': 'Test MVP',
                'why_now': 'Test timing'
            },
            'cross_source_validation': {
                'has_cross_source': False,
                'validation_level': 0,
                'boost_score': 0.0,
                'validated_problem': False
            }
        }
    ]

    # Temporarily override the output directory
    original_dir = generator.config['output']['markdown_dir']
    generator.config['output']['markdown_dir'] = tmp_path

    # Generate the report
    report_path = generator._export_markdown_report(shortlist)

    # Read the report content
    with open(report_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Restore original directory
    generator.config['output']['markdown_dir'] = original_dir

    # Verify no badge is in the report
    assert 'INDEPENDENT VALIDATION' not in content
    assert 'Multi-Subreddit Validation' not in content
    assert 'Weak Cross-Source Signal' not in content
    assert 'Validated Problem**: âŒ No' in content


def test_sort_priority_key():
    """æµ‹è¯•è·¨æºéªŒè¯æ’åºé”®å‡½æ•°"""
    generator = DecisionShortlistGenerator()

    # Create test candidates with different validation levels
    candidates = [
        {
            'opportunity_name': 'No Validation - Low Score',
            'final_score': 6.0,
            'cluster_size': 10,
            'cross_source_validation': {'validation_level': 0}
        },
        {
            'opportunity_name': 'Level 3 - High Score',
            'final_score': 9.0,
            'cluster_size': 20,
            'cross_source_validation': {'validation_level': 3}
        },
        {
            'opportunity_name': 'Level 1 - Medium Score',
            'final_score': 8.0,
            'cluster_size': 15,
            'cross_source_validation': {'validation_level': 1}
        },
        {
            'opportunity_name': 'Level 2 - High Score',
            'final_score': 8.5,
            'cluster_size': 25,
            'cross_source_validation': {'validation_level': 2}
        },
        {
            'opportunity_name': 'No Validation - High Score',
            'final_score': 9.5,
            'cluster_size': 30,
            'cross_source_validation': {'validation_level': 0}
        }
    ]

    # Sort using the priority key function
    sorted_candidates = sorted(candidates, key=generator._sort_priority_key)

    # Verify order: Level 1 > Level 2 > Level 3 > No validation
    assert sorted_candidates[0]['opportunity_name'] == 'Level 1 - Medium Score'
    assert sorted_candidates[1]['opportunity_name'] == 'Level 2 - High Score'
    assert sorted_candidates[2]['opportunity_name'] == 'Level 3 - High Score'
    assert sorted_candidates[3]['opportunity_name'] == 'No Validation - High Score'
    assert sorted_candidates[4]['opportunity_name'] == 'No Validation - Low Score'


def test_sort_priority_key_same_level():
    """æµ‹è¯•åŒä¸€éªŒè¯ç­‰çº§å†…æŒ‰æœ€ç»ˆè¯„åˆ†å’Œèšç±»å¤§å°æ’åº"""
    generator = DecisionShortlistGenerator()

    # Create candidates with same validation level but different scores
    candidates = [
        {
            'opportunity_name': 'Level 1 - Low Score - Small Cluster',
            'final_score': 7.0,
            'cluster_size': 10,
            'cross_source_validation': {'validation_level': 1}
        },
        {
            'opportunity_name': 'Level 1 - High Score - Large Cluster',
            'final_score': 9.0,
            'cluster_size': 30,
            'cross_source_validation': {'validation_level': 1}
        },
        {
            'opportunity_name': 'Level 1 - Medium Score - Medium Cluster',
            'final_score': 8.0,
            'cluster_size': 20,
            'cross_source_validation': {'validation_level': 1}
        }
    ]

    # Sort using the priority key function
    sorted_candidates = sorted(candidates, key=generator._sort_priority_key)

    # Within same validation level, sort by final_score (desc), then cluster_size (desc)
    assert sorted_candidates[0]['opportunity_name'] == 'Level 1 - High Score - Large Cluster'
    assert sorted_candidates[1]['opportunity_name'] == 'Level 1 - Medium Score - Medium Cluster'
    assert sorted_candidates[2]['opportunity_name'] == 'Level 1 - Low Score - Small Cluster'


def test_sort_priority_key_same_score_different_cluster():
    """æµ‹è¯•ç›¸åŒæœ€ç»ˆè¯„åˆ†æ—¶æŒ‰èšç±»å¤§å°æ’åº"""
    generator = DecisionShortlistGenerator()

    # Create candidates with same final score but different cluster sizes
    candidates = [
        {
            'opportunity_name': 'Level 2 - Small Cluster',
            'final_score': 8.0,
            'cluster_size': 10,
            'cross_source_validation': {'validation_level': 2}
        },
        {
            'opportunity_name': 'Level 2 - Large Cluster',
            'final_score': 8.0,
            'cluster_size': 30,
            'cross_source_validation': {'validation_level': 2}
        },
        {
            'opportunity_name': 'Level 2 - Medium Cluster',
            'final_score': 8.0,
            'cluster_size': 20,
            'cross_source_validation': {'validation_level': 2}
        }
    ]

    # Sort using the priority key function
    sorted_candidates = sorted(candidates, key=generator._sort_priority_key)

    # Same final score, sort by cluster_size (desc)
    assert sorted_candidates[0]['opportunity_name'] == 'Level 2 - Large Cluster'
    assert sorted_candidates[1]['opportunity_name'] == 'Level 2 - Medium Cluster'


def test_json_report_includes_cross_source_validation(tmp_path):
    """æµ‹è¯•JSONæŠ¥å‘ŠåŒ…å«å®Œæ•´çš„è·¨æºéªŒè¯ä¿¡æ¯"""
    import os
    from unittest.mock import patch

    generator = DecisionShortlistGenerator()

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    shortlist = [
        {
            'opportunity_name': 'Test Opportunity Level 1',
            'final_score': 9.5,
            'viability_score': 8.5,
            'cluster_size': 25,
            'trust_level': 0.85,
            'target_users': 'Developers',
            'missing_capability': 'API integration',
            'why_existing_fail': 'Too complex',
            'readable_content': {'description': 'Test description'},
            'cross_source_validation': {
                'has_cross_source': True,
                'validation_level': 1,
                'validated_problem': True,
                'boost_score': 1.5,
                'evidence': 'Found in both Reddit and Hacker News'
            }
        },
        {
            'opportunity_name': 'Test Opportunity No Validation',
            'final_score': 7.5,
            'viability_score': 7.5,
            'cluster_size': 15,
            'trust_level': 0.75,
            'target_users': 'Data Scientists',
            'missing_capability': 'Data processing',
            'why_existing_fail': 'Too slow',
            'readable_content': {'description': 'Test description 2'},
            'cross_source_validation': {
                'has_cross_source': False,
                'validation_level': 0,
                'validated_problem': False,
                'boost_score': 0.0,
                'evidence': ''
            }
        }
    ]

    # Mock config to use tmp_path
    with patch.object(generator, 'config', {
        'output': {
            'json_dir': str(tmp_path),
            'markdown_dir': str(tmp_path)
        }
    }):
        # Generate JSON report
        report_path = generator._export_json_report(shortlist)

        # Verify file was created
        assert os.path.exists(report_path)

        # Read and verify JSON content
        with open(report_path, 'r', encoding='utf-8') as f:
            report_data = json.load(f)

        # Verify structure
        assert 'generated_at' in report_data
        assert 'total_candidates' in report_data
        assert report_data['total_candidates'] == 2
        assert 'candidates' in report_data
        assert len(report_data['candidates']) == 2

        # Verify first candidate has enhanced cross_source_validation
        candidate1 = report_data['candidates'][0]
        assert 'cross_source_validation' in candidate1
        csv1 = candidate1['cross_source_validation']

        # Check all 6 fields are present
        assert 'has_cross_source' in csv1
        assert 'validation_level' in csv1
        assert 'validated_problem' in csv1
        assert 'boost_score' in csv1
        assert 'evidence' in csv1
        assert 'badge_text' in csv1

        # Verify values
        assert csv1['has_cross_source'] == True
        assert csv1['validation_level'] == 1
        assert csv1['validated_problem'] == True
        assert csv1['boost_score'] == 1.5
        assert csv1['evidence'] == 'Found in both Reddit and Hacker News'
        assert 'INDEPENDENT VALIDATION ACROSS REDDIT + HACKER NEWS' in csv1['badge_text']

        # Verify second candidate (no validation)
        candidate2 = report_data['candidates'][1]
        csv2 = candidate2['cross_source_validation']
        assert csv2['has_cross_source'] == False
        assert csv2['validation_level'] == 0
        assert csv2['badge_text'] == ''


def test_json_report_badge_text_levels(tmp_path):
    """æµ‹è¯•ä¸åŒéªŒè¯çº§åˆ«çš„å¾½ç« æ–‡æœ¬"""
    import os
    from unittest.mock import patch

    generator = DecisionShortlistGenerator()

    # åˆ›å»ºæµ‹è¯•æ•°æ® - åŒ…å«æ‰€æœ‰éªŒè¯çº§åˆ«
    shortlist = [
        {
            'opportunity_name': 'Level 1 Opportunity',
            'final_score': 9.0,
            'viability_score': 8.0,
            'cluster_size': 20,
            'trust_level': 0.8,
            'target_users': 'Users',
            'missing_capability': 'Feature',
            'why_existing_fail': 'Reason',
            'readable_content': {},
            'cross_source_validation': {
                'has_cross_source': True,
                'validation_level': 1,
                'validated_problem': True,
                'boost_score': 1.5,
                'evidence': 'Multi-platform'
            }
        },
        {
            'opportunity_name': 'Level 2 Opportunity',
            'final_score': 8.0,
            'viability_score': 7.5,
            'cluster_size': 15,
            'trust_level': 0.75,
            'target_users': 'Users',
            'missing_capability': 'Feature',
            'why_existing_fail': 'Reason',
            'readable_content': {},
            'cross_source_validation': {
                'has_cross_source': True,
                'validation_level': 2,
                'validated_problem': False,
                'boost_score': 0.5,
                'evidence': 'Multi-subreddit'
            }
        },
        {
            'opportunity_name': 'Level 3 Opportunity',
            'final_score': 7.0,
            'viability_score': 7.0,
            'cluster_size': 10,
            'trust_level': 0.7,
            'target_users': 'Users',
            'missing_capability': 'Feature',
            'why_existing_fail': 'Reason',
            'readable_content': {},
            'cross_source_validation': {
                'has_cross_source': True,
                'validation_level': 3,
                'validated_problem': False,
                'boost_score': 0.2,
                'evidence': 'Weak signal'
            }
        }
    ]

    # Mock config
    with patch.object(generator, 'config', {
        'output': {
            'json_dir': str(tmp_path),
            'markdown_dir': str(tmp_path)
        }
    }):
        report_path = generator._export_json_report(shortlist)

        with open(report_path, 'r', encoding='utf-8') as f:
            report_data = json.load(f)

        candidates = report_data['candidates']

        # Level 1 badge
        assert 'INDEPENDENT VALIDATION ACROSS REDDIT + HACKER NEWS' in candidates[0]['cross_source_validation']['badge_text']

        # Level 2 badge
        assert 'Multi-Subreddit Validation' in candidates[1]['cross_source_validation']['badge_text']

        # Level 3 badge
        assert 'Weak Cross-Source Signal' in candidates[2]['cross_source_validation']['badge_text']

